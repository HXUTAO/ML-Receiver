{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from other direction. Itis necessary if the project is structured as:\n",
    "# my_project\n",
    "# ├── notebooks\n",
    "# │   └── Generate Radio Data for tr.ipynb\n",
    "# ├── local_python_package\n",
    "# │   ├── __init__.py\n",
    "# │   ├── models.py\n",
    "# ├── README.md\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from radioml.dataset import RadioData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LEN = 200\n",
    "PREAMBLE_LEN = 40\n",
    "CHANNEL_LEN = 1\n",
    "\n",
    "SNR_TRAIN = 20.0\n",
    "OMEGA_TRAIN = 1/50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GRU, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def cfo_network(preamble, preamble_conv, scope=\"CFOCorrectionNet\"):\n",
    "    \"\"\"Build CFO Correction Network\n",
    "    Arguments:\n",
    "        preamble :     tf.Tensor float32 -  [batch, preamble_length, 2]\n",
    "        preamble_conv: tf.Tensor float32 -  [batch, preamble_length, 2]\n",
    "        \n",
    "    Return:\n",
    "        cfo_est: tf.Tensor float32 - [batch_size, 1]\n",
    "    \"\"\"\n",
    "    with tf.name_scope(scope):\n",
    "        inputs = tf.keras.layers.concatenate([preamble, preamble_conv], axis=-1,\n",
    "                                            name='Preamble_PreambleConv')\n",
    "        inputs = tf.keras.layers.Flatten()(inputs)\n",
    "        x = Dense(100, 'tanh',  name=scope+\"_dense_1\")(inputs)\n",
    "        x = Dense(100, 'tanh',  name=scope+\"_dense_2\")(x)\n",
    "        x = Dense(100, 'tanh',  name=scope+\"_dense_3\")(x)\n",
    "        cfo_est = Dense(1, 'linear', name='CFOEstimate')(x)\n",
    "        \n",
    "    return cfo_est\n",
    "\n",
    "\n",
    "def equalization_network(cfo_corrected_packets, cfo_corrected_preamble, preamble):\n",
    "    \"\"\"Given a [preamble, preambe_conv] and \"\"\"\n",
    "    \n",
    "    with tf.name_scope('ChannelEstimateNet'):\n",
    "        inputs = tf.keras.layers.concatenate([preamble, cfo_corrected_preamble], axis=-1,\n",
    "                                            name='Preamble_RotatedPreamble')\n",
    "        inputs = tf.keras.layers.Flatten()(inputs)\n",
    "        x = Dense(300, 'relu')(inputs)\n",
    "        x = Dense(300, 'relu')(x)\n",
    "        x = Dense(2, 'sigmoid', name='ChannelEsitate')(x)\n",
    "        \n",
    "    chan_est = RepeatVector(200)(x)\n",
    "    inputs = tf.keras.layers.concatenate([cfo_corrected_packets, chan_est], axis=-1,\n",
    "                                        name=\"CFOCorrected_ChannelEstimate\")\n",
    "    with tf.name_scope('EqualizationNet'):\n",
    "        x = Bidirectional(LSTM(45, return_sequences=True))(inputs)\n",
    "        x = Bidirectional(LSTM(45, return_sequences=True))(x)\n",
    "        x = TimeDistributed(Dense(100, activation='relu'))(x)\n",
    "        x = TimeDistributed(Dense(2, activation='linear'))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def demod_and_ecc_network(equalized_packets):\n",
    "    with tf.name_scope('DemodAndDecodeNet'):\n",
    "        x = Bidirectional(LSTM(400, 'selu', return_sequences=True))(equalized_packets)\n",
    "        x = Bidirectional(LSTM(400, 'selu', return_sequences=True))(x)\n",
    "        \n",
    "    data_estimates = TimeDistributed(Dense(1, activation='sigmoid'), name='DataEstimate')(x)\n",
    "    \n",
    "    return data_estimates\n",
    "\n",
    "def cfo_correction_func(kwargs):\n",
    "    \"\"\"Rotate packets given an omega estimate \n",
    "    \n",
    "    Arguments:\n",
    "        omega_estimate: tf.Tensor float32 - [batch, 1]\n",
    "        packets:        tf.Tensor float32 - [batch, (preamble_len + data_len), 2] \n",
    "        \n",
    "    Return:\n",
    "        rotated_packets: tf.Tensor float32 - [batch, (preamble_len + data_len), 2] \n",
    "    \"\"\" \n",
    "    # Because of Lambda Layer, we need to pass arguments as Kwargs\n",
    "    omega_estimate, packets = kwargs[0], kwargs[1]\n",
    "\n",
    "    # Build rotation matrix\n",
    "    with tf.name_scope('rotation_matrix'):\n",
    "        packet_len      = tf.cast(tf.shape(packets)[1], tf.float32) # preamble_len + data_len\n",
    "        rotation_matrix = tf.exp(tf.complex(0.0, - 1.0 * omega_estimate * tf.range(packet_len)))\n",
    "\n",
    "    # CFO Correction \n",
    "    with tf.name_scope('cfo_correction'):\n",
    "        rotated_packets = tf.complex(packets[..., 0], packets[...,1]) * rotation_matrix\n",
    "\n",
    "    # Encode complex packets into 2D array\n",
    "    with tf.name_scope('corrected_preamble'):\n",
    "        corrected_preambe = tf.stack([tf.real(rotated_packets)[..., :PREAMBLE_LEN], \n",
    "                                      tf.imag(rotated_packets)[..., :PREAMBLE_LEN]], \n",
    "                                      axis=-1)\n",
    "    with tf.name_scope('rotated_packets'):\n",
    "        rotated_packets = tf.stack([tf.real(rotated_packets)[..., PREAMBLE_LEN:], \n",
    "                                      tf.imag(rotated_packets)[..., PREAMBLE_LEN:]], \n",
    "                                      axis=-1)\n",
    "        \n",
    "    return corrected_preambe, rotated_packets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build a  Gigantic Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training parameters: 5385466\n"
     ]
    }
   ],
   "source": [
    "preamble          = Input(shape=(40, 2), name='preamble')\n",
    "preamble_conv     = Input(shape=(40, 2), name='preamble_conv')\n",
    "corrupted_packets = Input(shape=(240, 2), name='corrupted_packets')  # [preamble_conv, data_conv]\n",
    "\n",
    " \n",
    "cfo_est = cfo_network(preamble, preamble_conv)\n",
    "cfo_corrected_preamble, cfo_corrected_packets = \\\n",
    "    Lambda(cfo_correction_func,name='CFO_Correction')(\n",
    "            [cfo_est, corrupted_packets])\n",
    "\n",
    "equalized_packets = equalization_network(cfo_corrected_packets, cfo_corrected_preamble, preamble)\n",
    "data_estimates    = demod_and_ecc_network(equalized_packets)\n",
    "\n",
    "model = tf.keras.Model([corrupted_packets, preamble, preamble_conv], data_estimates)\n",
    "\n",
    "print(\"Number of training parameters: %d\" % model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0929f90d9c49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SVG' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import SVG, display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import numpy as np\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:800px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:820px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepcom",
   "language": "python",
   "name": "deepcom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
