\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\addvspace {10pt}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.1}{\ignorespaces The effects of a two tap channel on the QPSK constellation.\relax }}{3}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.2}{\ignorespaces The effects of a carrier frequency offset on the QPSK constellation.\relax }}{5}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.3}{\ignorespaces The effects of a two tap channel and a carrier frequency offset on the QPSK constellation.\relax }}{7}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.4}{\ignorespaces The impacts of multipath channels and initial phase offsets on bit error performance \cite {osheaatt}.\relax }}{8}
\defcounter {refsection}{0}\relax 
\addvspace {10pt}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.1}{\ignorespaces Topographical surface representation of the division function; $z=\frac {x}{y}$.\relax }}{11}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.2}{\ignorespaces Neural network divsion with respect to the lower bound of $y$.\relax }}{12}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Topographical surface representation of the multiplication function; $z=xy$.\relax }}{13}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Neural network divsion with respect to the upper bound of $y$.\relax }}{14}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Comparison of RNN and MMSE mean squared error after equalization.\relax }}{14}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.6}{\ignorespaces What two tap channels does the equalizer get wrong?\relax }}{15}
\defcounter {refsection}{0}\relax 
\addvspace {10pt}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.1}{\ignorespaces Linear neural network: follow a circle for a constant CFO rate.\relax }}{18}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.2}{\ignorespaces Nonlinear neural network: follow a circle for a different CFO rates.\relax }}{18}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.3}{\ignorespaces The log BER of received signals passed through a neural network CFO estimator with a rotation matrix CFO correction and classic demodulator. The log BER of the same signals passed through just the classic demodulator.\relax }}{20}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.4}{\ignorespaces Nonlinear neural network estimating and correcting CFO for different $\omega $. In this particular test example, $\omega =0.00969545$ and SNR$=\infty $.\relax }}{20}
\defcounter {refsection}{0}\relax 
\addvspace {10pt}
